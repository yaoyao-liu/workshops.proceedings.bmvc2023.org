<!doctype html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="description" content="The website for the 34th British Machine Vision Conference."><script src="/cdn-cgi/apps/head/VB9iiBJCCF8qrI8c3zDlJCb25P8.js"></script><link rel="stylesheet" href="./assets/css/bootstrap.min.css"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous"><link rel="stylesheet" href="./assets/css/ndfc.css"><link rel="apple-touch-icon" sizes="180x180" href="./assets/favicon/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="./assets/favicon/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="./assets/favicon/favicon-16x16.png"><link rel="manifest" href="./assets/favicon/site.webmanifest"><link rel="mask-icon" href="./assets/favicon/safari-pinned-tab.svg" color="#5bbad5"><meta name="msapplication-TileColor" content="#da532c"><meta name="theme-color" content="#ffffff"><title>The 34th British Machine Vision Conference 2023: Workshop Papers</title></head><header></header><body>


    <nav class="navbar sticky-top navbar-expand-md navbar-dark bg-primary"><div class="container"><a class="navbar-brand" href="https://bmvc2023.org/"><b class="ndfc-brand-light">BMVC&thinsp;2023</b></a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavDropdown" aria-controls="navbarNavDropdown" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse" id="navbarNavDropdown"><ul class="navbar-nav mr-auto"></ul><ul class="navbar-nav"></ul></div> </div></nav>


    <div class="container m-t-2"><div class="page-header" style="padding-bottom: 9px; margin: 20px 0 20px; border-bottom: 1px solid #eee;"><div class="row align-items-center"><div class="col-xs-12 mx-auto"><h1 style="text-align: center;">The 34<sup>th</sup> BMVC Workshop Proceedings</h1></div></div></div></div><main role="main" class="container"><div class="row pl-2 pr-2 pt-2 pb-2 mx-auto justify-content-left">

    <p>If there are any mistakes on this page, please do not hesitate to contact <a href="mailt:yyliu@cs.jhu.edu">yyliu@cs.jhu.edu</a></p>

    <table class="table table-striped table-bordered" style=""><tbody><a style="visibility: hidden;">-1</a>

    <tr id="paper"><td class="text-center"><strong> </strong><br /><span style="opacity: 0.5;"><strong>1</strong></span></td><td><strong><a href="./ComputerVisionforGamesandGamesforComputerVisionWorkshop/2/CameraReady/Weak_Supervision_for_Label_Efficient_Visual_Bug_Detection_bmvc-1.pdf">Weak Supervision for Label Efficient Visual Bug Detection</a></strong><br />Farrukh Rahman<br />

    <a class="btn btn-primary btn-sm mt-1" href="./ComputerVisionforGamesandGamesforComputerVisionWorkshop/2/CameraReady/Weak_Supervision_for_Label_Efficient_Visual_Bug_Detection_bmvc-1.pdf" role="button">PDF</a>&nbsp;

    </td></tr>

    <tr id="paper"><td class="text-center"><strong> </strong><br /><span style="opacity: 0.5;"><strong>2</strong></span></td><td><strong><a href="./ComputerVisionforGamesandGamesforComputerVisionWorkshop/3/CameraReady/NST_in_Computer_Games__BMVC_2023.pdf">Neural Style Transfer for Computer Games</a></strong><br />Eleftherios Ioannou, Steve Maddock<br />

    <a class="btn btn-primary btn-sm mt-1" href="./ComputerVisionforGamesandGamesforComputerVisionWorkshop/3/CameraReady/NST_in_Computer_Games__BMVC_2023.pdf" role="button">PDF</a>&nbsp;

    </td></tr>

    <tr id="paper"><td class="text-center"><strong> </strong><br /><span style="opacity: 0.5;"><strong>3</strong></span></td><td><strong><a href="./ComputerVisionforGamesandGamesforComputerVisionWorkshop/4/CameraReady/CVG23_BMVC_Decomposing_Game_Representations_into_Style_and_Content.pdf">Towards General Game Representations: Decomposing Games Pixels into Content and Style</a></strong><br />Chintan Trivedi, Konstantinos Makantasis, Antonios Liapis, Georgios N. Yannakakis<br />

    <a class="btn btn-primary btn-sm mt-1" href="./ComputerVisionforGamesandGamesforComputerVisionWorkshop/4/CameraReady/CVG23_BMVC_Decomposing_Game_Representations_into_Style_and_Content.pdf" role="button">PDF</a>&nbsp;

    </td></tr>

    <tr id="paper"><td class="text-center"><strong> </strong><br /><span style="opacity: 0.5;"><strong>4</strong></span></td><td><strong><a href="./ComputerVisionforGamesandGamesforComputerVisionWorkshop/5/CameraReady/BMVC_CGV.pdf">STEP CATFormer: Spatial-Temporal Effective Body-Part Cross Attention Transformer for Skeleton-based Action Recognition</a></strong><br />Bao Long Nguyen Huu, Tohgoroh Matsui<br />

        <a class="btn btn-primary btn-sm mt-1" href="./ComputerVisionforGamesandGamesforComputerVisionWorkshop/5/CameraReady/BMVC_CGV.pdf" role="button">PDF</a>&nbsp;

    </td></tr>

    <tr id="paper"><td class="text-center"><strong> </strong><br /><span style="opacity: 0.5;"><strong>5</strong></span></td><td><strong><a href="./ComputerVisionforGamesandGamesforComputerVisionWorkshop/6/CameraReady/CVG2023-3.pdf">Self-Avatar’s Animation in VR: Extending Sparse Motion Features with Cartesian Coordinates in Transformer-based Model</a></strong><br />Antoine Maiorca, Thierry Ravet, Thierry Dutoit<br />

        <a class="btn btn-primary btn-sm mt-1" href="./ComputerVisionforGamesandGamesforComputerVisionWorkshop/6/CameraReady/CVG2023-3.pdf" role="button">PDF</a>&nbsp;

    </td></tr>

    <tr id="paper"><td class="text-center"><strong> </strong><br /><span style="opacity: 0.5;"><strong>6</strong></span></td><td><strong><a href="./InternationalWorkshoponComputationalAspectsofDeepLearning/1/CameraReady/bmvc_Towards Robot Anomaly Detection.pdf">Towards Robot Anomaly Detection</a></strong><br />Ken Miyamoto, Masato Tsuchiya, Takashi Ota, Lee Teng-Yok<br />

        <a class="btn btn-primary btn-sm mt-1" href="./InternationalWorkshoponComputationalAspectsofDeepLearning/1/CameraReady/bmvc_Towards Robot Anomaly Detection.pdf" role="button">PDF</a>&nbsp;

        <a class="btn btn-primary btn-sm mt-1" href="./InternationalWorkshoponComputationalAspectsofDeepLearning/1/CameraReady/bmvc_Supplementary Material.pdf" role="button">Supplementary Material</a>&nbsp;

    </td></tr>

    <tr id="paper"><td class="text-center"><strong> </strong><br /><span style="opacity: 0.5;"><strong>7</strong></span></td><td><strong><a href="./InternationalWorkshoponComputationalAspectsofDeepLearning/3/CameraReady/AMP_CameraReady.pdf">A Practical Mixed Precision Algorithm for Post-Training Quantization</a></strong><br />Nilesh Prasad Pandey, Markus Nagel, Mart van Baalen, Yin Huang, Chirag Patel, Tijmen Blankevoort<br />

        <a class="btn btn-primary btn-sm mt-1" href="./InternationalWorkshoponComputationalAspectsofDeepLearning/3/CameraReady/AMP_CameraReady.pdf" role="button">PDF</a>&nbsp;


    </td></tr>
    <tr id="paper"><td class="text-center"><strong> </strong><br /><span style="opacity: 0.5;"><strong>8</strong></span></td><td><strong><a href="./The1stWorkshopinVideoUnderstandinganditsApplications/1/CameraReady/BMVC2023_Workshop.pdf">Self-supervised animal detection in constrained environment</a></strong><br />Fayaz Rahman et al.<br />

        <a class="btn btn-primary btn-sm mt-1" href="./The1stWorkshopinVideoUnderstandinganditsApplications/1/CameraReady/BMVC2023_Workshop.pdf" role="button">PDF</a>&nbsp;


    </td></tr>

    <tr id="paper"><td class="text-center"><strong> </strong><br /><span style="opacity: 0.5;"><strong>9</strong></span></td><td><strong><a href="./The1stWorkshopinVideoUnderstandinganditsApplications/2/CameraReady/CRC_VUA_BMVC_2023.pdf">ZeST-NeRF: Using temporal aggregation for Zero-Shot Temporal NeRFs</a></strong><br />Violeta Menéndez González, Andrew Gilbert, Graeme Phillipson, Stephen Jolly, Simon Hadfield<br />

        <a class="btn btn-primary btn-sm mt-1" href="./The1stWorkshopinVideoUnderstandinganditsApplications/2/CameraReady/CRC_VUA_BMVC_2023.pdf" role="button">PDF</a>&nbsp;

        <a class="btn btn-primary btn-sm mt-1" href="./The1stWorkshopinVideoUnderstandinganditsApplications/2/CameraReady/CRC_VUA_BMVC_2023_supp.pdf" role="button">Supplementary Material</a>&nbsp;

    </td></tr>

    <tr id="paper"><td class="text-center"><strong> </strong><br /><span style="opacity: 0.5;"><strong>10</strong></span></td><td><strong><a href="./The1stWorkshopinVideoUnderstandinganditsApplications/3/CameraReady/BMVCWorkshop_2023_Actor_Context_Attentions.pdf">Actor and Context Attentions for Spatio-Temporal Action Localization</a></strong><br />Manuel Sarmiento, David Varas, Elisenda Bou-Balust<br />

        <a class="btn btn-primary btn-sm mt-1" href="./The1stWorkshopinVideoUnderstandinganditsApplications/3/CameraReady/BMVCWorkshop_2023_Actor_Context_Attentions.pdf" role="button">PDF</a>&nbsp;


    </td></tr>

    <tr id="paper"><td class="text-center"><strong> </strong><br /><span style="opacity: 0.5;"><strong>11</strong></span></td><td><strong><a href="./The1stWorkshopinVideoUnderstandinganditsApplications/4/CameraReady/VUA_2023_4_Camera_ready.pdf">Centre Stage: Centricity-based Audio-Visual Temporal Action Detection</a></strong><br />Hanyuan Wang, Majid Mirmehdi, Dima Damen, Toby Perrett<br />

        <a class="btn btn-primary btn-sm mt-1" href="./The1stWorkshopinVideoUnderstandinganditsApplications/4/CameraReady/VUA_2023_4_Camera_ready.pdf" role="button">PDF</a>&nbsp;


    </td></tr>

    <tr id="paper"><td class="text-center"><strong> </strong><br /><span style="opacity: 0.5;"><strong>12</strong></span></td><td><strong><a href="./The1stWorkshopinVideoUnderstandinganditsApplications/5/CameraReady/Amodal_Video_Instance_Segmentation__BMVC_-6_cameraready.pdf">End-to-end Amodal Video Instance Segmentation</a></strong><br />Jasmin Breitenstein, Kangdong Jin, Aziz Hakiri, Marvin Klingner, Tim Fingscheidt<br />

        <a class="btn btn-primary btn-sm mt-1" href="./The1stWorkshopinVideoUnderstandinganditsApplications/5/CameraReady/Amodal_Video_Instance_Segmentation__BMVC_-6_cameraready.pdf" role="button">PDF</a>&nbsp;
        <a class="btn btn-primary btn-sm mt-1" href="./The1stWorkshopinVideoUnderstandinganditsApplications/5/CameraReady/Amodal_Video_Instance_Segmentation___Supplement__BMVC_-cameraready.pdf" role="button">Supplementary Material</a>&nbsp;

    </td></tr>

    <tr id="paper"><td class="text-center"><strong> </strong><br /><span style="opacity: 0.5;"><strong>13</strong></span></td><td><strong><a href="./The1stWorkshopinVideoUnderstandinganditsApplications/6/CameraReady/O_Laurendin_Pedestrian_and_Automatic_VUA_BMVC_2023.pdf">Pedestrian and Automatic Doors Abnormal Interactions Detection using Multi-Task Self-Supervised Learning</a></strong><br />Olivier Laurendin, Sébastien Ambellouis, Ankur Mahtani, Anthony Fleury<br />

        <a class="btn btn-primary btn-sm mt-1" href="./The1stWorkshopinVideoUnderstandinganditsApplications/6/CameraReady/O_Laurendin_Pedestrian_and_Automatic_VUA_BMVC_2023.pdf" role="button">PDF</a>&nbsp;
        <a class="btn btn-primary btn-sm mt-1" href="./The1stWorkshopinVideoUnderstandinganditsApplications/6/CameraReady/BMVC_VUA_Workshop_Additionnal_Data.pdf" role="button">Supplementary Material</a>&nbsp;

    </td></tr>

    <tr id="paper"><td class="text-center"><strong> </strong><br /><span style="opacity: 0.5;"><strong>14</strong></span></td><td><strong><a href="./WorkshoponMachineVisionforEarthObservation/5/CameraReady/mveo_RL.pdf">An a contrario approach for plant disease detection</a></strong><br />Rebecca Leygonie, Sylvain Lobry, Laurent Wendling<br />

        <a class="btn btn-primary btn-sm mt-1" href="./WorkshoponMachineVisionforEarthObservation/5/CameraReady/mveo_RL.pdf" role="button">PDF</a>&nbsp;
    </td></tr>

    <tr id="paper"><td class="text-center"><strong> </strong><br /><span style="opacity: 0.5;"><strong>15</strong></span></td><td><strong><a href="./WorkshoponMachineVisionforEarthObservation/6/CameraReady/6.pdf">Multi-task prompt-RSVQA to explicitly count objects on aerial images</a></strong><br />Christel Chappuis et al.<br />

        <a class="btn btn-primary btn-sm mt-1" href="./WorkshoponMachineVisionforEarthObservation/6/CameraReady/6.pdf" role="button">PDF</a>&nbsp;
    </td></tr>

    <tr id="paper"><td class="text-center"><strong> </strong><br /><span style="opacity: 0.5;"><strong>16</strong></span></td><td><strong><a href="./WorkshoponMachineVisionforEarthObservation/7/CameraReady/final_submission.pdf">Contrastive Maximum Mean Discrepancy for Unsupervised Domain Adaptation Applied to Large Scale 3D LiDAR Semantic Segmentation</a></strong><br />Lamiae El Mendili, Sylvie Daniel, Thierry Badard, Patrick Dallaire<br />

        <a class="btn btn-primary btn-sm mt-1" href="./WorkshoponMachineVisionforEarthObservation/7/CameraReady/final_submission.pdf" role="button">PDF</a>&nbsp;
    </td></tr>

    <tr id="paper"><td class="text-center"><strong> </strong><br /><span style="opacity: 0.5;"><strong>17</strong></span></td><td><strong><a href="./WorkshoponMachineVisionforEarthObservation/8/CameraReady/SUBMIT_BMVA_workshop.pdf">Computer Vision Pipeline for Automated Antarctic Krill Analysis</a></strong><br />Mazvydas Gudelis, Michal Mackiewicz, Julie Bremner, Sophie Fielding<br />

        <a class="btn btn-primary btn-sm mt-1" href="./WorkshoponMachineVisionforEarthObservation/8/CameraReady/SUBMIT_BMVA_workshop.pdf" role="button">PDF</a>&nbsp;
    </td></tr>

    </tbody></table></div></main><footer class="footer bg-light"><div class="container"><div class="row align-items-center footer-row"><div class="col-xs-12 col-sm-12 col-lg-5 col-xl-5 pb-2 pt-2"><b>© 2023 The <a href="https://britishmachinevisionassociation.github.io/">BMVA</a></b><br><a href="https://imprint.mpi-klsb.mpg.de/inf/bmvc2022.mpi-inf.mpg.de">Imprint</a> &nbsp; <a href="https://data-protection.mpi-klsb.mpg.de/inf/bmvc2022.mpi-inf.mpg.de?lang=en">Data Protection</a></div><div class="col-xs-12 col-sm-12 col-lg-5 col-xl-7 pb-2 pt-2" style="font-size:10px;">The British Machine Vision Conference is organised by <a href="https://britishmachinevisionassociation.github.io/">The British Machine Vision Association and Society for Pattern Recognition</a>. The Association is a Company limited by guarantee, No.2543446, and a non-profit-making body, registered in England and Wales as Charity No.1002307 (Registered Office: Dept. of Computer Science, Durham University, South Road, Durham, DH1 3LE, UK).<br><p hidden><script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=wzUkN24cyDxLTiWGAKIGs6eT1DdKPGAZctgXfZX1Qxs"></script></p></div></div></footer><script data-cfasync="false" src="/cdn-cgi/scripts/5c5dd728/cloudflare-static/email-decode.min.js"></script><script src="/assets/js/jquery-3.5.1.slim.min.js"></script><script src="/assets/js/popper.min.js"></script><script src="/assets/js/bootstrap.min.js"></script><script src="/assets/js/jquery.date-filter.min.js"></script><script>$(document).ready(function(){/*console.log("Hello");*//*console.log($(".date-filter"));*/$(".date-filter").dateFilter();$(".date-older-filter").dateOlderFilter();});</script></body></html>
        

    
